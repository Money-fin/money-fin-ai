{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Embedding\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.utils import pprint\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from models import *\n",
    "from utils import DataLoader2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "ETA = 1e-3\n",
    "# torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dloader = DataLoader(10)\n",
    "train_loader = DataLoader2(BATCH_SIZE, mode=\"train\")\n",
    "valid_loader = DataLoader2(BATCH_SIZE, mode=\"valid\")\n",
    "test_loader = DataLoader2(BATCH_SIZE, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_clf = SentimentPredictor().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(sentiment_clf.parameters(), lr=ETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(preds, y):\n",
    "    preds[preds >= 0.5] = 1\n",
    "    preds[preds < 0.5] = 0\n",
    "    \n",
    "    return torch.mean((y == preds).type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y):\n",
    "    N = len(x)\n",
    "    preds = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for doc in x:\n",
    "        try:\n",
    "            embeddeds = []\n",
    "            for sen in doc:\n",
    "                embedded = Embedding.get_sentiment_vector(sen).cuda().detach()\n",
    "                embeddeds.append(embedded.view(1, 1, -1))\n",
    "\n",
    "            embedded = torch.cat(embeddeds, dim=1)\n",
    "\n",
    "            pred = sentiment_clf(embedded)\n",
    "            preds.append(pred)\n",
    "        except:\n",
    "            print(sen)\n",
    "            print(embedded.shape)\n",
    "            print(pred)\n",
    "        \n",
    "    preds = torch.stack(preds, dim=0).view(-1)\n",
    "            \n",
    "    loss_0 = bce_criterion(preds[y == 0], y[y == 0])\n",
    "    loss_1 = bce_criterion(preds[y == 1], y[y == 1])\n",
    "    loss = (5/6)*loss_0 + (1/6)*loss_1\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    acc = compute_accuracy(preds, y)\n",
    "    \n",
    "    return loss.item(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(x, y):\n",
    "    N = len(x)\n",
    "    preds = []\n",
    "    \n",
    "    for doc in x:\n",
    "        embeddeds = []\n",
    "        for sen in doc:\n",
    "            embedded = Embedding.get_sentiment_vector(sen).cuda().detach()\n",
    "            embeddeds.append(embedded.view(1, 1, -1))\n",
    "            \n",
    "        embedded = torch.cat(embeddeds, dim=1)\n",
    "        \n",
    "        pred = sentiment_clf(embedded)\n",
    "        preds.append(pred)\n",
    "        \n",
    "    preds = torch.stack(preds, dim=0).view(-1)\n",
    "            \n",
    "    loss_0 = bce_criterion(preds[y == 0], y[y == 0])\n",
    "    loss_1 = bce_criterion(preds[y == 1], y[y == 1])\n",
    "    loss = (5/6)*loss_0 + (1/6)*loss_1\n",
    "    acc = compute_accuracy(preds, y)\n",
    "    \n",
    "    return loss.item(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mode():\n",
    "    #sentence_enc.train()\n",
    "    #context_enc.train()\n",
    "    #mine_est.train()\n",
    "    sentiment_clf.train()\n",
    "\n",
    "def eval_mode():\n",
    "    #sentence_enc.eval()\n",
    "    #context_enc.eval()\n",
    "    #mine_est.eval()\n",
    "    sentiment_clf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "    \n",
    "    for e in range(EPOCHS):\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        train_mode()\n",
    "        \n",
    "        for x, y in train_loader.next_batch():\n",
    "            y = torch.FloatTensor(y).cuda()\n",
    "            loss, acc = train_step(x, y)\n",
    "            train_loss += loss\n",
    "            train_acc += acc\n",
    "        \n",
    "            clear_output(wait=True)\n",
    "            print(f\"train loss: {loss:.6f}, train acc: {acc:.4f}\")\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "            \n",
    "        eval_mode()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y in valid_loader.next_batch():\n",
    "                y = torch.FloatTensor(y).cuda()\n",
    "                loss, acc = test_step(x, y)\n",
    "                valid_loss += loss\n",
    "                valid_acc += acc\n",
    "        \n",
    "                clear_output(wait=True)\n",
    "                print(f\"valid loss: {loss:.6f}, valid acc: {acc:.4f}\")\n",
    "                \n",
    "        valid_loss /= len(valid_loader)\n",
    "        valid_acc /= len(valid_loader)\n",
    "        \n",
    "        valid_accs.append(valid_acc)\n",
    "        \n",
    "        torch.save(sentiment_clf, \"ckpts/sentiment_clf.pt\")\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "\n",
    "        print(f\"Epochs {e+1}/{EPOCHS}\")\n",
    "        print(f\"Train loss: {train_loss:.6f}, train acc: {train_acc:.4f}, valid acc: {valid_acc:.4f}\")\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        \n",
    "        axes[0].plot(train_losses)\n",
    "        axes[0].set_title(\"train loss\")\n",
    "        axes[0].set_xlabel(\"epochs\")\n",
    "        axes[0].set_ylabel(\"loss\")\n",
    "        \n",
    "        axes[1].plot(train_accs)\n",
    "        axes[1].set_title(\"train acc\")\n",
    "        axes[1].set_xlabel(\"epochs\")\n",
    "        axes[1].set_ylabel(\"acc\")\n",
    "        \n",
    "        axes[2].plot(valid_accs)\n",
    "        axes[2].set_title(\"valid acc\")\n",
    "        axes[2].set_xlabel(\"epochs\")\n",
    "        axes[2].set_ylabel(\"acc\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.539572, train acc: 0.1719\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
